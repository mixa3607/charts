# Helm package for vllm

A high-throughput and memory-efficient inference and serving engine for LLMs

## TL;DR

```console
helm install my-release oci://ghcr.io/mixa3607/charts/vllm
```

## Prerequisites

- Kubernetes 1.30+
- Helm 3.8.0+
